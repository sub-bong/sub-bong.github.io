---
title: "순차 데이터 처리를 위한 순환 신경망 (RNN)"
date: "2025-08-15"
keywords: ["TIL", "RNN"]
---

# 순차 데이터 처리를 위한 순환 신경망 (RNN)

## 순차 데이터 (Sequential Data)란?

- **정의**: 데이터 샘플 간에 **시간적 또는 공간적 순서 관계**가 존재하는 데이터입니다. 각 데이터 포인트가 독립적이지 않고 서로 연관되어 있습니다. (예: 텍스트, 시계열 데이터, 음성, DNA 서열)
- **텍스트 데이터**: 단어들의 순서가 문장의 의미를 결정하는 대표적인 순차 데이터입니다. 순차 데이터를 처리하는 각 단계를 **타임 스텝(Time Step)**이라고 합니다. (예: "I am a boy" -> 4개의 타임 스텝)

## 텍스트 데이터의 정형화: 텍스트 마이닝

- **텍스트 마이닝**: 비정형 텍스트 데이터를 분석 가능한 형태의 **정형 데이터**로 변환하는 과정입니다.
- **기본 전처리 과정**:
  1.  **코퍼스(Corpus, 말뭉치) 준비**: 분석 대상이 되는 텍스트 데이터 집합을 준비합니다.
  2.  **토큰화 (Tokenization)**: 텍스트를 의미 있는 최소 단위인 **토큰(Token)**(주로 단어)으로 분할합니다.
  3.  **정제 (Cleaning)**: 불필요한 문장 부호나 숫자 등을 제거하고, 영문의 경우 모두 소문자로 변환합니다.
  4.  **불용어 (Stop words) 제거**: 문장에서 큰 의미를 가지지 않는 단어(예: a, the, is, 조사, 접미사 등)를 제거합니다.
  5.  **어간 추출 (Stemming) / 표제어 추출 (Lemmatization)**: 단어의 원형을 찾아 단어를 정규화합니다. (예: studies, studying -> study)
  6.  **정수 인코딩 (Integer Encoding)**: 각 단어에 고유한 정수를 부여하여 숫자로 맵핑합니다. 보통 단어의 빈도수 순서로 정수를 부여합니다.

## 순환 신경망 (Recurrent Neural Network, RNN)

- **등장 배경**: CNN이나 일반적인 DNN은 타임 스텝 간의 순서 정보를 기억하지 못하여 순차 데이터 처리에 한계가 있습니다.
- **핵심 구조**: RNN은 **순환(Recurrent)** 구조를 통해 이전 타임 스텝의 정보를 현재 타임 스텝의 입력으로 다시 사용하는 신경망입니다. 뉴런의 출력이 다시 자기 자신에게 피드백으로 들어가는 구조를 가집니다.
- **은닉 상태 (Hidden State)**: RNN의 **셀(Cell)**은 각 타임 스텝에서 입력(x)과 이전 타임 스텝의 **은닉 상태(h)**를 함께 받아 현재 타임 스텝의 은닉 상태를 계산하고, 이를 다음 타임 스텝으로 전달합니다. 이 은닉 상태가 바로 **문맥(Context)을 기억**하는 역할을 합니다.

## RNN의 한계: 장기 의존성 문제

- **기울기 소실/폭주 (Vanishing/Exploding Gradient)**: RNN은 타임 스텝이 길어질수록(즉, 문장이 길어질수록) 역전파 과정에서 기울기가 0으로 수렴하거나 무한대로 발산하는 문제가 발생합니다.
- **장기 의존성 문제 (Long-Term Dependency Problem)**: 기울기 소실 문제로 인해, 문장의 앞부분에 있는 중요한 정보가 뒤쪽 타임 스텝까지 제대로 전달되지 못하는 현상입니다. 이로 인해 RNN은 긴 문장의 의미를 파악하는 데 어려움을 겪습니다.

## LSTM (Long Short-Term Memory): 장기 기억 셀

- **개념**: RNN의 장기 의존성 문제를 해결하기 위해 고안된 발전된 형태의 RNN 셀 구조입니다.
- **핵심 원리**: 기존 RNN의 은닉 상태 외에, 장기 기억을 위한 **셀 상태(Cell State)**라는 별도의 정보 흐름을 가집니다. 그리고 **게이트(Gate)**라는 장치를 통해 셀 상태에 어떤 정보를 추가하고, 어떤 정보를 잊어버릴지를 선택적으로 제어합니다.
  - **Forget Gate**: 과거의 정보 중 어떤 것을 잊을지 결정합니다.
  - **Input Gate**: 현재 정보 중 어떤 것을 셀 상태에 저장할지 결정합니다.
  - **Output Gate**: 셀 상태의 정보 중 어떤 것을 현재 타임 스텝의 출력으로 내보낼지 결정합니다.
- **효과**: 중요한 정보는 오래 기억하고, 중요하지 않은 정보는 잊어버리는 메커니즘을 통해 장기 의존성 문제를 효과적으로 해결합니다.
