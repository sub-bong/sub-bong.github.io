---
title: "객체 검출(Object Detection) 모델의 발전"
date: "2025-08-22"
keywords: ["TIL", "컴퓨터 비전", "객체 검출"]
---

# 객체 검출(Object Detection) 모델의 발전

객체 검출은 이미지 내에 존재하는 모든 객체의 **종류(Class)**를 분류하고, 그 **위치**를 경계 상자(Bounding Box)로 정확하게 찾아내는 과제입니다. 분류(Classification)보다 한 단계 더 나아간 복잡한 문제입니다.

## 2-Stage Detectors: 정확도를 위한 두 단계 접근

2-Stage Detector는 **1) 객체가 있을 만한 후보 영역을 먼저 찾고, 2) 각 후보 영역에 대해 분류를 수행**하는 두 단계 접근 방식을 사용합니다. 정확도가 높지만 속도가 느리다는 특징이 있습니다.

### 1. R-CNN (Regions with CNN features)

- **처리 과정**:
  1.  **영역 제안 (Region Proposal)**: **선택적 탐색(Selective Search)** 알고리즘을 사용하여 이미지에서 객체가 있을 만한 후보 영역(Region of Interest, RoI)을 약 2,000개 생성합니다.
  2.  **특징 추출 (Feature Extraction)**: 각 후보 영역을 모두 동일한 크기(예: 227x227)로 변형시킨 후, 개별적으로 CNN 모델에 입력하여 고정된 차원의 특징 벡터(예: 4096차원)를 추출합니다.
  3.  **분류 및 위치 보정 (Classification & Regression)**: 추출된 특징 벡터를 **SVM(Support Vector Machine)** 분류기에 넣어 객체의 클래스를 판별하고, 선형 회귀 모델을 통해 경계 상자의 위치를 미세하게 조정합니다.
- **한계**: 수천 개의 후보 영역 각각에 대해 CNN 연산을 수행해야 하므로 속도가 매우 느립니다.

### 2. Fast R-CNN

- **개선점**: R-CNN의 속도 문제를 해결하기 위해, 후보 영역을 먼저 찾는 대신 **이미지 전체에 대해 CNN 연산을 딱 한 번만 수행**하여 특징 맵(Feature Map)을 만듭니다.
- **처리 과정**:
  1.  이미지 전체에 대해 CNN을 적용하여 특징 맵을 추출합니다.
  2.  선택적 탐색으로 찾은 각 후보 영역(RoI)을 특징 맵에 투영합니다.
  3.  **RoI 풀링(Pooling)**을 통해 각기 다른 크기의 후보 영역으로부터 고정된 크기의 특징 벡터를 추출합니다.
  4.  추출된 벡터를 완전 연결 층(FC Layer)과 두 개의 브랜치(분류용 Softmax, 위치 보정용 회귀)에 전달하여 결과를 동시에 얻습니다.
- **한계**: 여전히 영역 제안 단계에서 선택적 탐색을 사용하기 때문에, 이 부분이 병목으로 작용합니다.

### 3. Faster R-CNN

- **개선점**: Fast R-CNN의 병목이었던 선택적 탐색 알고리즘을 딥러닝 기반의 **영역 제안 네트워크(Region Proposal Network, RPN)**로 대체하여, 전체 과정을 End-to-End 딥러닝 모델로 통합했습니다.
- **처리 과정**: RPN은 CNN 특징 맵을 입력받아, 다양한 크기와 비율의 **앵커 박스(Anchor Box)**를 기준으로 객체가 있을 확률과 위치를 빠르게 계산하여 후보 영역을 제안합니다. 이후 과정은 Fast R-CNN과 동일합니다.
- **의의**: RPN의 도입으로 속도와 정확도를 모두 획기적으로 개선하여, 2-Stage Detector의 표준으로 자리 잡았습니다.

## 1-Stage Detectors: 속도를 위한 한 번의 접근

1-Stage Detector는 후보 영역 제안과 분류를 통합하여, **이미지를 한 번만 보고 객체의 위치와 종류를 동시에 예측**합니다. 속도가 매우 빠르지만, 초기 모델들은 2-Stage 방식에 비해 정확도가 다소 낮았습니다.

### YOLO (You Only Look Once)

- **핵심 아이디어**: 객체 검출을 별도의 분류 문제가 아닌, 하나의 **회귀(Regression)** 문제로 접근합니다.
- **처리 과정**:
  1.  입력 이미지를 특정 크기의 **격자(Grid)**로 나눕니다.
  2.  각 격자 셀(Grid Cell)은 자신이 맡은 영역의 객체를 예측할 책임을 집니다. 즉, 객체의 중심점이 특정 격자 셀 안에 위치하면, 그 셀이 해당 객체를 예측합니다.
  3.  각 격자 셀은 **경계 상자의 위치(x, y, w, h), 신뢰도(Confidence Score), 클래스 확률(Class Probability)**을 포함하는 벡터를 직접 예측합니다.
- **장점**: 구조가 매우 간단하고, 후보 영역을 찾는 과정이 없어 압도적으로 빠른 속도를 자랑하여 실시간 객체 검출에 널리 사용됩니다.
- **YOLOv3**: 다양한 크기의 특징 맵(Multi-scale features)을 사용하여, 기존 YOLO가 어려움을 겪었던 작은 객체에 대한 검출 성능을 크게 향상시켰습니다.
