const n=`---
title: "CNN과 RNN의 핵심 개념 및 활용"
date: "2025-08-20"
keywords: ["TIL", "CNN", "RNN"]
---

# CNN과 RNN의 핵심 개념 및 활용

## CNN 심화: 필터와 인코더-디코더 구조

### 필터(Filter)의 역할

- **개념**: CNN의 필터(커널)는 특정 패턴을 감지하는 역할을 합니다. 이 필터가 이미지 위를 지나가며 합성곱 연산을 수행함으로써, 이미지의 **지역 특징(local feature)**을 추출하여 **특징 맵(feature map)**을 생성합니다.
- **이상적인 필터**: 결국 CNN의 학습 목표는, 주어진 문제를 해결하는 데 가장 이상적인 특징을 추출할 수 있는 **최적의 필터 가중치**를 찾는 것입니다.
- **필터의 종류와 효과**:
  - **스무딩/블러링 (Smoothing/Blurring)**: 주변 픽셀 값들을 평균 내는 필터. 이미지의 노이즈를 줄이고 표면을 매끄럽게 만들어, 불필요한 엣지(edge)가 검출되는 것을 방지합니다.
  - **샤프닝 (Sharpening)**: 경계선의 대비를 강조하는 필터. 엣지를 더욱 선명하게 만들어 특징을 부각시키는 효과를 줍니다.

### 인코더-디코더 (Encoder-Decoder) 구조

- **개념**: 입력 데이터를 저차원의 잠재 벡터(latent vector)로 압축하는 **인코더**와, 이 벡터를 다시 원래 데이터의 형태로 복원하는 **디코더**로 구성된 구조입니다.
- **CNN에서의 활용**:
  - **인코더**: 합성곱(Convolution)과 풀링(Pooling) 층을 반복적으로 쌓아, 이미지의 차원을 점차 줄여나가며 핵심 특징을 압축합니다.
  - **디코더**: 업샘플링(Up-sampling)과 합성곱 층을 통해, 압축된 특징 벡터로부터 다시 원래 해상도의 이미지나 마스크(mask)를 생성합니다.
- **주요 활용 분야**: 이미지 분할(Semantic Segmentation)에 사용되는 U-Net이나, 이미지 생성 모델인 오토인코더(Autoencoder) 등에서 핵심적인 구조로 사용됩니다.

## RNN 심화: 장기 기억 셀과 다양한 입출력 구조

### 장기 기억 문제 해결

- **LSTM (Long Short-Term Memory)**: RNN의 장기 의존성 문제를 해결하기 위해 등장했습니다. **셀 상태(Cell State)**라는 별도의 기억 공간과 3개의 **게이트(Forget, Input, Output)**를 통해, 어떤 정보를 오래 기억하고 어떤 정보를 잊을지 선택적으로 제어합니다.
- **GRU (Gated Recurrent Unit)**: LSTM의 장점을 유지하면서 구조를 단순화한 모델입니다. 게이트의 수를 2개로 줄여 파라미터가 적고 계산 효율이 높기 때문에, 경우에 따라 LSTM보다 선호되기도 합니다.

### 순차 데이터의 다양한 입출력 구조

RNN 계열 모델은 입출력 시퀀스의 형태에 따라 다양한 문제에 적용될 수 있습니다.

- **일대일 (One-to-One)**: 단일 입력, 단일 출력 (예: 이미지 분류)
- **일대다 (One-to-Many)**: 단일 입력, 시퀀스 출력 (예: 이미지 캡셔닝 - 이미지를 입력받아 설명 문장을 생성)
- **다대일 (Many-to-One)**: 시퀀스 입력, 단일 출력 (예: 감성 분석 - 문장을 입력받아 긍정/부정 레이블을 출력)
- **다대다 (Many-to-Many)**: 시퀀스 입력, 시퀀스 출력
  - **동기식**: 입력과 출력이 동기화됨 (예: 개체명 인식 - 각 단어에 대한 태그를 출력)
  - **비동기식**: 입력이 모두 끝난 후 출력이 시작됨 (예: 기계 번역 - 영어 문장 전체를 입력받은 후 한국어 문장을 생성)
`;export{n as default};
